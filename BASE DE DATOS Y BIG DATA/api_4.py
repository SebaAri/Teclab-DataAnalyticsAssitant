# -*- coding: utf-8 -*-
"""API-4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12oTR-DxA-4XKJ3wT34fIb23JRmHawCaN
"""

# Instalamos pyspark
!pip install pyspark

# Importamos las bibliotecas necesarias
from pyspark.sql import SparkSession

# Creamos una sesión de Spark
spark = SparkSession.builder.appName("migracion-sql-a-spark").getOrCreate()

# Importamos otras bibliotecas necesarias
from pyspark.sql.types import StructType, StructField, IntegerType, StringType

# Creamos una sesión de Spark
spark = SparkSession.builder.appName("consulta-spark").getOrCreate()

# Definimos un esquema para los datos de ejemplo
schema = StructType([
    StructField("idArticulo", IntegerType(), False),
    StructField("Idnumero", IntegerType(), False),
    StructField("TipoArticulo", StringType(), False),
    StructField("DescripcionArticulo", StringType(), False),
    StructField("Scanning", IntegerType(), False),
    StructField("UxB", IntegerType(), False),
    StructField("StockDiaAnterior", IntegerType(), False)
])

# Creamos un DataFrame de Spark con datos de ejemplo
data = [
    (1, 101, 'Tipo1', 'Descripción1', 100, 5, 500),
    (2, 102, 'Tipo2', 'Descripción2', 200, 6, 600),
    (3, 103, 'Tipo3', 'Descripción3', 150, 4, 450)
]

df = spark.createDataFrame(data, schema=schema)

# Registramos el DataFrame como una tabla en Spark
df.createOrReplaceTempView("datamart_foto_stock")

# Ejecutamos la consulta original
consulta_spark = """
SELECT
    idArticulo AS IDARTICULO,
    Idnumero AS IDNUMERO,
    TipoArticulo AS TIPOARTICULO,
    DescripcionArticulo AS DESCRIPCIONARTICULO,
    Scanning,
    UxB,
    StockDiaAnterior AS STOCKDIAANTERIO
FROM
    datamart_foto_stock
"""

resultado = spark.sql(consulta_spark)
resultado.show()

# Cerramos la sesión de Spark cuando haya terminado
spark.stop()

# Define el código SQL para crear el esquema y la tabla en Spark
creacion_esquema_tabla = """
CREATE DATABASE IF NOT EXISTS datamart_proveedores;
CREATE TABLE IF NOT EXISTS datamart_proveedores.PROVEEDORES (
    IdProveedor INT PRIMARY KEY,
    NombreProveedor STRING,
    Direccion STRING,
    Telefono STRING,
    Email STRING
)
"""

# Importa las bibliotecas necesarias
from pyspark.sql import SparkSession

# Crea una sesión de Spark
spark = SparkSession.builder.appName("migracion-sql-a-spark").getOrCreate()

# Define el código SQL para crear la tabla en Spark
creacion_tabla = """
CREATE OR REPLACE TEMPORARY VIEW PROVEEDORES AS
SELECT
    1 AS IdProveedor, 'Proveedor1' AS NombreProveedor, 'Mitre 256' AS Direccion, '011-456-7890' AS Telefono, 'proveedor1@yahoo.com' AS Email
UNION ALL
SELECT
    2 AS IdProveedor, 'Proveedor2' AS NombreProveedor, 'Estomba 1203' AS Direccion, '011-654-3210' AS Telefono, 'proveedor2@hotmail.com' AS Email
UNION ALL
SELECT
    3 AS IdProveedor, 'Proveedor3' AS NombreProveedor, 'Urquiza 128' AS Direccion, '0291-922-4633' AS Telefono, 'proveedor3@gmail.com' AS Email
"""

# Ejecuta el código SQL para crear la tabla
spark.sql(creacion_tabla)

# Define la consulta para obtener los datos
consulta_datos = """
SELECT
    IdProveedor AS IDPROVEEDOR,
    NombreProveedor AS NOMBREPROVEEDOR,
    Direccion AS DIRECCION,
    Telefono AS TELEFONO,
    Email AS EMAIL
FROM
    PROVEEDORES
"""

# Ejecuta la consulta para obtener los datos
resultado = spark.sql(consulta_datos)

# Muestra el resultado
resultado.show()

# Cierra la sesión de Spark cuando hayas terminado
spark.stop()

# Importa las bibliotecas necesarias
from pyspark.sql import SparkSession

# Crea una sesión de Spark
spark = SparkSession.builder.appName("migracion-sql-a-spark").getOrCreate()

# Define el código SQL para crear la tabla en Spark
creacion_tabla = """
CREATE OR REPLACE TEMPORARY VIEW ESCANEO_PRODUCTOS AS
SELECT
    1 AS IdEscaneo, 1 AS idArticulo, 101 AS Idnumero, 'Tipo1' AS TipoArticulo, 'Descripción1' AS DescripcionArticulo, 120 AS Scanning, 5 AS UxB, 550 AS StockActual
UNION ALL
SELECT
    2 AS IdEscaneo, 2 AS idArticulo, 102 AS Idnumero, 'Tipo2' AS TipoArticulo, 'Descripción2' AS DescripcionArticulo, 210 AS Scanning, 6 AS UxB, 590 AS StockActual
UNION ALL
SELECT
    3 AS IdEscaneo, 3 AS idArticulo, 103 AS Idnumero, 'Tipo3' AS TipoArticulo, 'Descripción3' AS DescripcionArticulo, 155 AS Scanning, 4 AS UxB, 455 AS StockActual
"""

# Ejecuta el código SQL para crear la tabla
spark.sql(creacion_tabla)

# Define la consulta para obtener los datos
consulta_datos = """
SELECT
    IdEscaneo AS IDESCANEO,
    idArticulo AS IDARTICULO,
    Idnumero AS IDNUMERO,
    TipoArticulo AS TIPOARTICULO,
    DescripcionArticulo AS DESCRIPCIONARTICULO,
    Scanning,
    UxB,
    StockActual AS STOCKACTUAL
FROM
    ESCANEO_PRODUCTOS
"""

# Ejecuta la consulta para obtener los datos
resultado = spark.sql(consulta_datos)

# Muestra el resultado
resultado.show()

# Cierra la sesión de Spark cuando hayas terminado
spark.stop()